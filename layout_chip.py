import json
from collections import defaultdict
from typing import List, Dict, Any

# --- å¸ƒå±€é…ç½® ---
# æ‚¨å¯ä»¥æ ¹æ®æœ€ç»ˆæ•ˆæœå¾®è°ƒè¿™äº›å€¼
X_SPACING = 800.0  # èŠ‚ç‚¹â€œåˆ—â€ä¹‹é—´çš„æ°´å¹³è·ç¦»
Y_SPACING = 600.0  # åŒä¸€åˆ—ä¸­èŠ‚ç‚¹ä¹‹é—´çš„æœ€å°å‚ç›´è·ç¦»
GLOBAL_X_OFFSET = -11000.0 # æ•´ä½“å‘å·¦å¹³ç§»ï¼Œä»¥é€‚åº”ç”»å¸ƒ

# --- æ–‡ä»¶å (ä»…åœ¨ç‹¬ç«‹è¿è¡Œæ—¶ä½¿ç”¨) ---
INPUT_FILENAME = 'ungraph.json'
OUTPUT_FILENAME = 'ungraph_layouted_ultimate.json'


# --- å…¨æ–°çš„â€œALAP + è´¨å¿ƒè¿­ä»£â€å¸ƒå±€å¼•æ“ ---

def parse_graph(nodes: List[Dict[str, Any]]) -> tuple:
    """è§£æèŠ‚ç‚¹åˆ—è¡¨ï¼Œæ„å»ºå¸ƒå±€æ‰€éœ€çš„æ•°æ®ç»“æ„ã€‚"""
    predecessors = defaultdict(list)
    successors = defaultdict(list)
    node_map = {node['Id']: node for node in nodes}

    for node_id, node in node_map.items():
        for input_port in node.get('Inputs', []):
            connection = input_port.get('connectedOutputIdModel')
            if connection and 'NodeId' in connection:
                source_id = connection['NodeId']
                if source_id in node_map:
                    successors[source_id].append(node_id)
                    predecessors[node_id].append(source_id)
    return predecessors, successors, list(node_map.keys())

def calculate_alap_layers(node_ids: list, predecessors: dict, successors: dict) -> dict:
    """
    æ ¸å¿ƒå‡çº§ï¼šä½¿ç”¨ ALAP (As Late As Possible) ç®—æ³•åˆ†å±‚ã€‚
    è¿™ä¼šå°†èŠ‚ç‚¹å°½å¯èƒ½åœ°å‘å³æ¨ï¼Œé¿å…åœ¨ç¬¬ä¸€å±‚å †ç§¯ã€‚
    """
    # 1. å…ˆè¿›è¡Œä¸€æ¬¡ASAPï¼ˆä»å·¦åˆ°å³ï¼‰åˆ†å±‚ï¼Œä»¥ç¡®å®šå›¾çš„æ€»æ·±åº¦
    asap_layers = {}
    q = [n for n in node_ids if not predecessors[n]]
    for node_id in q: asap_layers[node_id] = 0
    
    head = 0
    processed_in_asap = set(q)
    while head < len(q):
        u = q[head]; head += 1
        for v in successors[u]:
            if v not in asap_layers:
                asap_layers[v] = 0
            asap_layers[v] = max(asap_layers[v], asap_layers[u] + 1)
            if v not in processed_in_asap:
                q.append(v)
                processed_in_asap.add(v)
    
    max_layer = max(asap_layers.values()) if asap_layers else 0

    # 2. è¿›è¡ŒALAPï¼ˆä»å³åˆ°å·¦ï¼‰åˆ†å±‚
    alap_layers = {}
    q = [n for n in node_ids if not successors[n]]
    for node_id in q: alap_layers[node_id] = max_layer
    
    head = 0
    processed_in_alap = set(q)
    while head < len(q):
        u = q[head]; head += 1
        for v in predecessors[u]:
            if v not in alap_layers:
                alap_layers[v] = max_layer
            alap_layers[v] = min(alap_layers[v], alap_layers[u] - 1)
            if v not in processed_in_alap:
                q.append(v)
                processed_in_alap.add(v)
            
    # å°†å±‚ä¿¡æ¯ç»„ç»‡æˆå­—å…¸
    layers_map = defaultdict(list)
    for node_id, layer in alap_layers.items():
        layers_map[layer].append(node_id)
        
    return layers_map

def iterative_barycenter_positioning(layers: dict, predecessors: dict, successors: dict) -> dict:
    """
    æ ¸å¿ƒå‡çº§ï¼šä½¿ç”¨å¤šè½®è´¨å¿ƒè¿­ä»£ä¼˜åŒ–å‚ç›´ä½ç½®ï¼Œä»¥æœ€å¤§ç¨‹åº¦å‡å°‘çº¿æ¡äº¤å‰ã€‚
    """
    positions = {}
    # åˆå§‹åŒ–Yåæ ‡
    for i in sorted(layers.keys()):
        for j, node_id in enumerate(layers[i]):
            positions[node_id] = {'y': j * Y_SPACING}

    # è¿›è¡Œå¤šè½®è¿­ä»£ä¼˜åŒ–
    for _ in range(10): # 10è½®è¿­ä»£é€šå¸¸è¶³å¤Ÿæ”¶æ•›
        # ä»å·¦åˆ°å³ pass (åŸºäºçˆ¶èŠ‚ç‚¹)
        for i in sorted(layers.keys()):
            for node_id in layers[i]:
                parent_ys = [positions[p]['y'] for p in predecessors[node_id] if p in positions]
                if parent_ys:
                    positions[node_id]['y'] = sum(parent_ys) / len(parent_ys)
        
        # ä»å³åˆ°å·¦ pass (åŸºäºå­èŠ‚ç‚¹)
        for i in sorted(layers.keys(), reverse=True):
            for node_id in layers[i]:
                child_ys = [positions[s]['y'] for s in successors[node_id] if s in positions]
                if child_ys:
                    positions[node_id]['y'] = sum(child_ys) / len(child_ys)

    return positions

def resolve_overlaps_and_finalize(layers: dict, temp_positions: dict) -> dict:
    """æœ€åä¸€æ­¥ï¼šè§£å†³é‡å ï¼Œå¹¶æœ€ç»ˆç¡®å®šX,Yåæ ‡ã€‚"""
    final_positions = {}
    for i in sorted(layers.keys()):
        # è¿‡æ»¤æ‰ä¸åœ¨ temp_positions ä¸­çš„èŠ‚ç‚¹ï¼Œä»¥é˜²ä¸‡ä¸€
        nodes_in_layer = sorted(
            [n for n in layers[i] if n in temp_positions],
            key=lambda n: temp_positions[n]['y']
        )
        
        # è§£å†³é‡å 
        for j in range(1, len(nodes_in_layer)):
            prev_node, curr_node = nodes_in_layer[j-1], nodes_in_layer[j]
            min_y = temp_positions[prev_node]['y'] + Y_SPACING
            if temp_positions[curr_node]['y'] < min_y:
                temp_positions[curr_node]['y'] = min_y
                
        # åˆ†é…æœ€ç»ˆåæ ‡
        for node_id in nodes_in_layer:
            final_positions[node_id] = {'x': i * X_SPACING, 'y': temp_positions[node_id]['y']}
            
    # å‚ç›´å±…ä¸­æ•´ä¸ªå¸ƒå±€
    all_ys = [pos['y'] for pos in final_positions.values()]
    if all_ys:
        center_offset = (min(all_ys) + max(all_ys)) / 2.0
        for node_id in final_positions:
            final_positions[node_id]['y'] -= center_offset
            
    return final_positions


def find_and_update_chip_graph(data: dict, final_positions: dict) -> bool:
    """åœ¨JSONä¸­æ‰¾åˆ°èŠ¯ç‰‡å›¾æ•°æ®å¹¶æ›´æ–°èŠ‚ç‚¹åæ ‡ã€‚"""
    try:
        # è·¯å¾„å¯èƒ½å› å­˜æ¡£ç»“æ„è€Œå¼‚ï¼Œè¿™é‡Œå‡è®¾æ˜¯æ ‡å‡†ç»“æ„
        save_obj = data['saveObjectContainers'][0]['saveObjects']
        for meta_data in save_obj['saveMetaDatas']:
            if meta_data.get('key') == 'chip_graph':
                graph_data = json.loads(meta_data['stringValue'])
                nodes_updated = 0
                for node in graph_data.get('Nodes', []):
                    if node['Id'] in final_positions:
                        pos = final_positions[node['Id']]
                        node['VisualPosition']['x'] = pos['x'] + GLOBAL_X_OFFSET
                        node['VisualPosition']['y'] = pos['y']
                        nodes_updated += 1
                
                if nodes_updated > 0:
                    meta_data['stringValue'] = json.dumps(graph_data, separators=(',', ':'))
                    print(f"   åœ¨'chip_graph'ä¸­æ›´æ–°äº† {nodes_updated} ä¸ªèŠ‚ç‚¹çš„ä½ç½®ã€‚")
                    return True
        print("   è­¦å‘Š: åœ¨JSONä¸­æ‰¾åˆ°äº†'chip_graph'ï¼Œä½†æ²¡æœ‰éœ€è¦æ›´æ–°åæ ‡çš„åŒ¹é…èŠ‚ç‚¹ã€‚")
        return False
    except (KeyError, IndexError, TypeError) as e:
        print(f"é”™è¯¯ï¼šå¯¼èˆªJSONç»“æ„æ—¶å‡ºé”™: {e}ã€‚è¯·æ£€æŸ¥å­˜æ¡£æ–‡ä»¶ç»“æ„æ˜¯å¦æ­£ç¡®ã€‚")
        return False

# --- æ–°å¢ï¼šå¯ä¾›å¤–éƒ¨è°ƒç”¨çš„ä¸»å‡½æ•° ---
def run_layout_engine(chip_nodes: List[Dict[str, Any]]) -> Dict[str, Dict[str, float]]:
    """
    æ¥æ”¶èŠ‚ç‚¹åˆ—è¡¨ï¼Œæ‰§è¡Œå®Œæ•´çš„å¸ƒå±€ç®—æ³•ï¼Œå¹¶è¿”å›æœ€ç»ˆä½ç½®ã€‚
    è¿™æ˜¯è¢« main.py è°ƒç”¨çš„æ ¸å¿ƒå…¥å£ã€‚
    """
    print("1. æ ¸å¿ƒæ­¥éª¤: æ‰§è¡Œ ALAP åˆ†å±‚...")
    predecessors, successors, node_ids = parse_graph(chip_nodes)
    layers = calculate_alap_layers(node_ids, predecessors, successors)
    print(f"   å®Œæˆã€‚å›¾è¢«åˆ†ä¸º {len(layers)} ä¸ªå±‚çº§ã€‚")

    print("2. æ ¸å¿ƒæ­¥éª¤: æ‰§è¡Œå¤šè½®è´¨å¿ƒè¿­ä»£...")
    temp_positions = iterative_barycenter_positioning(layers, predecessors, successors)
    print("   å®Œæˆã€‚")
    
    print("3. æœ€ç»ˆæ•´ç†: è§£å†³é‡å å¹¶å‚ç›´å±…ä¸­...")
    final_positions = resolve_overlaps_and_finalize(layers, temp_positions)
    print("   å®Œæˆã€‚")
    
    return final_positions

# --- ä¸»æ‰§è¡Œæµç¨‹ (ç”¨äºç‹¬ç«‹è¿è¡Œ) ---
if __name__ == '__main__':
    print("ğŸš€ å¯åŠ¨ç»ˆæå¸ƒå±€ç®—æ³• (ç‹¬ç«‹è¿è¡Œæ¨¡å¼)...")
    
    try:
        with open(INPUT_FILENAME, 'r', encoding='utf-8') as f:
            full_data = json.load(f)
        chip_graph_str = next(md['stringValue'] for md in full_data['saveObjectContainers'][0]['saveObjects']['saveMetaDatas'] if md['key'] == 'chip_graph')
        chip_nodes = json.loads(chip_graph_str).get('Nodes', [])
    except Exception as e:
        print(f"âŒ é”™è¯¯: æ— æ³•åœ¨ '{INPUT_FILENAME}' ä¸­è¯»å–æˆ–æ‰¾åˆ°èŠ¯ç‰‡æ•°æ®ã€‚è¯¦æƒ…: {e}")
        exit()

    print(f"âœ… æ‰¾åˆ° {len(chip_nodes)} ä¸ªèŠ‚ç‚¹ã€‚")
    
    # è°ƒç”¨æ–°çš„æ ¸å¿ƒå‡½æ•°
    final_positions = run_layout_engine(chip_nodes)

    print("4. ä½¿ç”¨æ–°åæ ‡æ›´æ–°JSONæ–‡ä»¶...")
    if find_and_update_chip_graph(full_data, final_positions):
        with open(OUTPUT_FILENAME, 'w', encoding='utf-8') as f:
            json.dump(full_data, f, indent=4) # ç‹¬ç«‹è¿è¡Œæ—¶ä½¿ç”¨ indent=4 æ–¹ä¾¿æŸ¥çœ‹
        print(f"\nğŸ‰ æˆåŠŸï¼å·²ç”Ÿæˆç»ˆæå¸ƒå±€æ–‡ä»¶: '{OUTPUT_FILENAME}'")
    else:
        print("âŒ è‡´å‘½é”™è¯¯: æ— æ³•åœ¨JSONæ–‡ä»¶ä¸­æ‰¾åˆ° 'chip_graph' ä»¥è¿›è¡Œæ›´æ–°ã€‚")